import sys
import os

current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)

import torch
import torch.nn as nn
import torch.nn.functional as F
import configparser

from data.ali_data import ali_dataset

# 创建一个配置解析器对象
config = configparser.ConfigParser()
# 读取INI文件
config.read('./config/config.ini')


# 词嵌入参数
vocab_size = len(ali_dataset.vocab_pkl) # 词表长度
embeddingDim = int(config['data']['embedding_dim']) # 词嵌入维度，一般是512
max_len = int(config['data']['sequence_max_len'])   # api截断长度,一般是512


# 训练参数
batch = int(config['VAEGAN']['batchSize']) # 训练批次
channel = int(config['VAEGAN']['channel'])  # channel倍数s

class VAE(nn.Module):
    def __init__(self):
        super(VAE, self).__init__()

        # 初始化参数
        self.channel = channel

        # 词嵌入
        # 将实现训练好的词向量导入
        # input:([batch, 512])
        self.embeding = nn.Embedding(vocab_size, embeddingDim, padding_idx=ali_dataset.vocab_pkl.PAD)    # ([batch, 512, 512])

        # Encoder
        # input:([batch, 1, 512, 512])
        self.encoder = nn.Sequential(
            nn.Conv2d(1, self.channel, 4, 2, 1),     # ([batch, 128, 256, 256])
            nn.ReLU(),

            nn.Conv2d(self.channel, self.channel * 2, 4, 2, 1),     # ([batch, 256, 128, 128])
            # nn.BatchNorm2d(self.channel * 2),
            nn.ReLU(),

            nn.Conv2d(self.channel * 2, self.channel * 4, 4, 2, 1), # ([batch, 512, 64, 64])
            # nn.BatchNorm2d(self.channel * 4),
            nn.ReLU(),

        )

        self.mu = nn.Conv2d(self.channel * 4, self.channel * 8, 4, 2, 1)    # ([batch, 1024, 32, 32])
        self.log = nn.Conv2d(self.channel * 4, self.channel * 8, 4, 2, 1)   # ([batch, 1024, 32, 32])

        # Decoder
        # input:([batch, 1024, 8, 8])
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(self.channel * 8, self.channel * 4, kernel_size=4, stride=2, padding=1, output_padding=0),  # ([batch, 512, 64, 64])
            # nn.BatchNorm2d(self.channel * 4),
            nn.ReLU(),

            nn.ConvTranspose2d(self.channel * 4, self.channel * 2, kernel_size=4, stride=2, padding=1, output_padding=0),  # ([batch, 256, 128, 128])
            # nn.BatchNorm2d(self.channel * 2),
            nn.ReLU(),

            nn.ConvTranspose2d(self.channel * 2, self.channel * 1, kernel_size=4, stride=2, padding=1, output_padding=0),  # ([batch, 128, 256, 256])
            # nn.BatchNorm2d(self.channel * 1),
            nn.ReLU(),

            nn.ConvTranspose2d(self.channel * 1, 1, kernel_size=4, stride=2, padding=1, output_padding=0),  # ([batch, 1, 512, 512])
            # nn.BatchNorm2d(1),
            nn.ReLU(),

            nn.Sigmoid()
        )


    def encode(self, x):
        x = self.embeding(x)
        x = x.view(x.size(0), 1, max_len, embeddingDim)
        y = x
        x = self.encoder(x)

        mu = self.mu(x)
        log = self.log(x)
        return mu,log,y

    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        reconstruction = self.decoder(z)
        return reconstruction

    def forward(self, x):
        mu,log,y = self.encode(x)  # ([batch, 1024, 32, 32])
        z = self.reparameterize(mu, log)    # ([batch, 1024, 32, 32])
        reconstruction = self.decode(z) # ([batch, 1, 512, 512])
        return mu, log, z, reconstruction, y


class Classifier(nn.Module):
    def __init__(self):
        # input: ([batch, 1024, 32, 32])
        super(Classifier, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1024, out_channels=256, kernel_size=3, stride=1, padding=1)  # ([1, 256, 16, 16])
        self.conv2 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)   # ([1, 128, 8, 8])
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.fc1 = nn.Linear(8192, 2048)
        self.fc2 = nn.Linear(2048, 512)
        self.fc3 = nn.Linear(512, 64)
        self.fc4 = nn.Linear(64, 8)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = F.relu(self.fc1(x.view(batch,-1)))
        x = self.fc2(x)
        nn.Dropout(0.3)
        x = self.fc3(x)
        x = self.fc4(x)
        return x


class Discriminator(nn.Module):
    pass