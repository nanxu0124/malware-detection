import sys
import os
current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)


from utils import utils

import torch
from tqdm import tqdm
from sklearn.metrics import recall_score, f1_score, accuracy_score

from torch.optim import Adam
from torch.optim.lr_scheduler import StepLR
from torch.autograd import Variable

import configparser
import pandas as pd
import torch.nn as nn

# 创建一个配置解析器对象
config = configparser.ConfigParser()
# 读取INI文件
config.read('./config/config.ini')


def TrainVAE(vae, train_loader, folder_path):

    print('VAE Model Training begin')

    VAE_Losses = []

    num_epochs = int(config['VAEGAN']['epochvae'])

    for epoch in range(num_epochs):

        running_loss = 0.0
        total_similarity = 0.0

        vae.train()
        vae_optim = Adam(vae.parameters(), lr = float(config['VAEGAN']['learning_rate']))

        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', ncols=100):
        # for inputs, labels in train_loader:

            # 设置device
            inputs = inputs.to(utils.device())

            # 清零梯度
            vae.zero_grad()

            mu, log, z, reconstruction, inputEmbedding = vae(inputs)

            # 计算重构损失
            recon_loss = nn.MSELoss()(reconstruction, inputEmbedding)
            
            # 计算相似度
            similarity = utils.SimiliarError(inputEmbedding, reconstruction)

            # 计算 KL 散度损失
            kl_loss = -0.5 * torch.sum(1 + log - mu.pow(2) - log.exp())

            loss = recon_loss + kl_loss
            loss.backward()
            vae_optim.step()

            running_loss += loss.item()
            total_similarity += similarity


        # 计算本次 epoch 的平均损失
        avg_loss = running_loss / len(train_loader)
        avg_similarity = total_similarity / len(train_loader)

        # 保存所有 epoch 的损失
        VAE_Losses.append(avg_loss)
                
        print(f'Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_loss:.6f} - avg_similarity: {avg_similarity:.6f}')
    
    utils.model_save(folder_path, (vae,))

    print('VAE-GAN Model Training finished')

    return VAE_Losses


def TrainCLA(vae, cla, train_loader, folder_path):

    print('CLA Model Training begin')

    CLA_Losses = []
    CLA_criterion = nn.CrossEntropyLoss(weight=
                                        torch.tensor([0.011750070912478906,
                                                    0.11651763546278883,
                                                    0.04890623160729097,
                                                    0.07133152805160975,
                                                    0.5849185300231999,
                                                    0.013637643507185822,
                                                    0.11357641359673785,
                                                    0.03936194683870794]).to(utils.device()))

    num_epochs = int(config['VAEGAN']['epochcla'])

    for epoch in range(num_epochs):

        running_loss = 0.0
        true_labels = []
        predicted_labels = []

        cla.train()
        cla_optim = Adam(cla.parameters(), lr = float(config['VAEGAN']['learning_rate']))

        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', ncols=100):

            # 设置device
            inputs = inputs.to(utils.device())
            labels = labels.to(utils.device())

            # 清零梯度
            cla.zero_grad()

            _, _, z, _, _ = vae(inputs)

            # 正向传播
            outputs = cla(z)
            loss = CLA_criterion(outputs, labels)

            # 反向传播和优化
            loss.backward()
            cla_optim.step()

            # 计算损失
            running_loss += loss.item()

            # 保存真实标签和预测标签以计算指标
            true_labels.extend(labels.tolist())
            _, predicted = torch.max(outputs, 1)
            predicted_labels.extend(predicted.tolist())

        # 计算本次 epoch 的平均损失
        avg_loss = running_loss / len(train_loader)

        # 保存所有 epoch 的损失
        CLA_Losses.append(avg_loss)
                
        # 计算召回率、F1-Score 和准确度
        recall = recall_score(true_labels, predicted_labels, average='weighted')
        f1 = f1_score(true_labels, predicted_labels, average='weighted')
        accuracy = accuracy_score(true_labels, predicted_labels)

        # 输出本次 epoch 的指标
        print(f'Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_loss:.4f} - Recall: {recall:.4f} - F1-Score: {f1:.4f} - Accuracy: {accuracy:.4f}')

    utils.model_save(folder_path, (cla,))

    print('CLAModel Training finished')

    return CLA_Losses



def Test(vae, cla, test_loader):

    # 设置模型为评估模式
    vae.eval()
    cla.eval()

    true_labels = []
    predicted_labels = []

    with torch.no_grad():  # 不需要计算梯度
        for inputs, labels in test_loader:

            # 设置device
            inputs = inputs.to(utils.device())
            labels = labels.to(utils.device())

            # 获取模型输出结果
            _, _, z, _, _ = vae(inputs)
            outputs = cla(z)

            _, predicted = torch.max(outputs, 1)
            
            # 保存真实标签和预测标签以计算指标
            true_labels.extend(labels.tolist())
            predicted_labels.extend(predicted.tolist())

    # 计算召回率、F1-Score 和准确度
    recall = recall_score(true_labels, predicted_labels, average='weighted')
    f1 = f1_score(true_labels, predicted_labels, average='weighted')
    accuracy = accuracy_score(true_labels, predicted_labels)

    # 输出测试指标
    print(f'Test Accuracy: {accuracy:.4f}')
    print(f'Test Recall: {recall:.4f}')
    print(f'Test F1-Score: {f1:.4f}')

    return recall, f1, accuracy
