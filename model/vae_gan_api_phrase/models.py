import sys
import os
current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)

import torch
import torch.nn as nn
import torch.nn.functional as F
import configparser
from data.ali_data.ali_dataset import vocab_pkl
config = configparser.ConfigParser()
config.read(os.path.join(project_dir,os.path.join("config", "config.ini")))

vocab_size = len(vocab_pkl)
embedding_dim = int(config['data']['embedding_dim'])
max_len = int(config['data']['sequence_max_len'])

batch = int(config['vae_gan_api_phrase']['batch_size'])
dim = int(config['vae_gan_api_phrase']['dim'])

class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.embeding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_pkl.PAD)

        self.conv = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(3, dim), stride=2, padding=(1, 0)),
            nn.ReLU(),

            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(4, 1), stride=2, padding=(1, 0)),
            nn.ReLU(),

            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(5, 1), stride=2, padding=(2, 0)),
            nn.ReLU(),
        )

        self.lstm = nn.LSTM(input_size=512, hidden_size=300, batch_first=True, bidirectional=True)

    def mu(self, x):

        x, (h_n, c_n) = self.lstm(x)
        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]

        y = torch.cat([output_fw, output_bw], dim=-1)

        return x, y
    
    def log(self, x):

        x, (h_n, c_n) = self.lstm(x)
        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]

        y = torch.cat([output_fw, output_bw], dim=-1)

        return x, y

    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x):

        x = self.embeding(x)
        x = x.view(x.size(0), 1, max_len, embedding_dim)
        embed_x = x
    
        x = self.conv(embed_x)
        x = x.permute(0, 3, 2, 1).squeeze(1)
        x_mu, y_mu = self.mu(x)
        x_log, y_log = self.log(x)

        z = self.reparameterize(x_mu ,x_log)

        return embed_x, z, x_mu, x_log, y_mu

class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        
        self.lstm = nn.LSTM(input_size=600, hidden_size=256, batch_first=True, bidirectional=True)

        self.deconv = nn.Sequential(
            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(5, 1), stride=2, padding=(2, 0), output_padding=(1, 0)),
            nn.ReLU(),

            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(4, 1), stride=2, padding=(1, 0)),
            nn.ReLU(),

            nn.ConvTranspose2d(in_channels=128, out_channels=1, kernel_size=(3, 16), stride=2, padding=(1, 0), output_padding=(1, 0)),
            nn.ReLU(),
        )
    
    def forward(self, x):

        x, (h_n, c_n) = self.lstm(x)
        x = x.permute(0,2, 1).unsqueeze(3)  # ([2, 512, 625, 1])

        x = self.deconv(x)

        return x


class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()

        self.lin1 = nn.Linear(600, 256)
        self.lin2 = nn.Linear(256, 64)
        self.lin3 = nn.Linear(64, 4)
        
    def forward(self, x):

        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.6, training=self.training)
        x = F.relu(self.lin2(x))
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.lin3(x)

        return x

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.main = nn.Sequential(
            nn.Linear(2048, 512),
            nn.ReLU(True),
            nn.Linear(512, 256),
            nn.ReLU(True),
            nn.Linear(256, 64),
            nn.ReLU(True),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = x.squeeze()
        x = self.main(x)
        return x


class API_Phrase(nn.Module):
    def __init__(self):
        super(API_Phrase, self).__init__()

        self.cnn1_1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(3, embedding_dim), stride=1, padding=(1, 0))
        self.cnn1_2 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(4, embedding_dim), stride=1)
        self.cnn1_3 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(5, embedding_dim), stride=1, padding=(2, 0))

        self.lstm = nn.LSTM(input_size=384, hidden_size=128, batch_first=True, bidirectional=True)


    def forward(self, x):

        pad = nn.ZeroPad2d(padding=(0, 0, 2, 1))
        x_pad = pad(x)

        x_name_cnn1 = F.relu(self.cnn1_1(x)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn2 = F.relu(self.cnn1_2(x_pad)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn3 = F.relu(self.cnn1_3(x)).squeeze(-1).permute(0, 2, 1)

        x = torch.cat([x_name_cnn1, x_name_cnn2, x_name_cnn3], dim=-1)

        x, (h_n, c_n) = self.lstm(x)

        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]

        x = torch.cat([output_fw, output_bw], dim=-1)
        x = x.view(x.size(0), x.size(1), 1, 1)

        return x