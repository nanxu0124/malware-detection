import sys
import os
current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)

import torch
import torch.nn as nn
import torch.nn.functional as F
import configparser
from data.ali_data.ali_dataset import vocab_pkl
config = configparser.ConfigParser()
config.read(os.path.join(project_dir,os.path.join("config", "config.ini")))

vocab_size = len(vocab_pkl)
embedding_dim = int(config['data']['embedding_dim'])
max_len = int(config['data']['sequence_max_len'])

batch = int(config['vae_gan_api_phrase']['batch_size'])
dim = int(config['vae_gan_api_phrase']['dim'])


class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()

        self.embeding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_pkl.PAD)

        self.encode = nn.Sequential(
            nn.Conv2d(1,dim,kernel_size=4,stride=2,padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(dim, dim * 2, 4, 2, 1,),
            nn.BatchNorm2d(dim * 2),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(dim * 2, dim * 4, 4, 2, 1),
            nn.BatchNorm2d(dim * 4),
            nn.ReLU(),
            nn.MaxPool2d(2), 

            nn.Conv2d(dim * 4, dim * 8, 4, 2, 1),
            nn.BatchNorm2d(dim * 8),
            nn.ReLU(),
            nn.MaxPool2d(2), 
        )

        self.mu = nn.Sequential(
            nn.Conv2d(dim * 8, dim * 16,2 , 1, 0),
            nn.BatchNorm2d(dim * 16),
            nn.ReLU(),
        )

        self.log = nn.Sequential(
            nn.Conv2d(dim * 8, dim * 16,2 , 1, 0),
            nn.BatchNorm2d(dim * 16),
            nn.ReLU(),
        )

    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x):

        x = self.embeding(x)
        x = x.view(x.size(0), 1, max_len, embedding_dim)
        embed_x = x

        x = self.encode(x)
        mu = self.mu(x)
        log = self.log(x)

        z = self.reparameterize(mu ,log)

        return mu, log, z, embed_x

class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()

        self.decode = nn.Sequential(
            nn.ConvTranspose2d(dim * 16, dim * 8, 4),
            nn.BatchNorm2d(dim * 8),
            nn.ReLU(),

            nn.ConvTranspose2d(dim * 8, dim * 4, kernel_size=5, stride=3,output_padding=2),
            nn.BatchNorm2d(dim * 4),
            nn.ReLU(),

            nn.ConvTranspose2d(dim * 4, dim * 2, kernel_size=4, stride=4,output_padding=0),
            nn.BatchNorm2d(dim * 2),
            nn.ReLU(),

            nn.ConvTranspose2d(dim * 2, dim * 1, kernel_size=4, stride=4,output_padding=0),
            nn.BatchNorm2d(dim * 1),
            nn.ReLU(),

            nn.ConvTranspose2d(dim * 1, 1, kernel_size=4, stride=2, padding=1, output_padding=0),
            nn.BatchNorm2d(1),
            nn.ReLU(),
        )

    def forward(self, x):
        x = x.view(batch, dim * 16, 1, 1)

        recon_x = self.decode(x)
        return recon_x


class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()

        self.lin1 = nn.Linear(2304, 1024)
        self.lin2 = nn.Linear(1024, 512)
        self.lin3 = nn.Linear(512, 256)
        self.lin4 = nn.Linear(256, 4)
        
    def forward(self, x):
        x = x.squeeze()
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.2, training=self.training)
        x = F.relu(self.lin2(x))
        x = F.dropout(x, p=0.2, training=self.training)
        x = F.relu(self.lin3(x))
        x = F.dropout(x, p=0.2, training=self.training)
        x = self.lin4(x)
        return x

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.main = nn.Sequential(
            nn.Linear(2048, 512),
            nn.ReLU(True),
            nn.Linear(512, 256),
            nn.ReLU(True),
            nn.Linear(256, 64),
            nn.ReLU(True),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = x.squeeze()
        x = self.main(x)
        return x


class API_Phrase(nn.Module):
    def __init__(self):
        super(API_Phrase, self).__init__()

        self.cnn1_1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(3, embedding_dim), stride=1, padding=(1, 0))
        self.cnn1_2 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(4, embedding_dim), stride=1)
        self.cnn1_3 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(5, embedding_dim), stride=1, padding=(2, 0))

        self.lstm = nn.LSTM(input_size=384, hidden_size=128, batch_first=True, bidirectional=True)


    def forward(self, x):

        pad = nn.ZeroPad2d(padding=(0, 0, 2, 1))
        x_pad = pad(x)

        x_name_cnn1 = F.relu(self.cnn1_1(x)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn2 = F.relu(self.cnn1_2(x_pad)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn3 = F.relu(self.cnn1_3(x)).squeeze(-1).permute(0, 2, 1)

        x = torch.cat([x_name_cnn1, x_name_cnn2, x_name_cnn3], dim=-1)

        x, (h_n, c_n) = self.lstm(x)

        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]

        x = torch.cat([output_fw, output_bw], dim=-1)
        x = x.view(x.size(0), x.size(1), 1, 1)

        return x