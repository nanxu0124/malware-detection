import sys
import os

current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)


import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from utils.utils import device, model_save, model_save_v2
from torch.optim import Adam
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import recall_score, f1_score, accuracy_score, precision_score, confusion_matrix
from data.ali_data.ali_dataset import ALiDataset, collate_fn_vocab
from utils.utils import device, create_folder, save_loss, model_info_save, plt_curve, setup_seed
from data.ali_data.ali_dataset import vocab_pkl
vocab_size = len(vocab_pkl)

class Statistic(nn.Module):
    def __init__(self):
        super(Statistic, self).__init__()
        self.cla = nn.Sequential(
            nn.Linear(80, 32),
            nn.ReLU(),
            nn.Linear(32, 6)
        )
        
    def forward(self, x):
        x = self.cla(x)
        return x

def TrainStatic(train_loader, test_loader, folder_path):
    print("Static Train begin")

    model = Statistic().to(device())
    StatisticLoss = []
    epochs = 32
    optimizer = Adam(model.parameters(), lr=0.005)

    for epoch in range(epochs):

        running_loss = 0.0
        true_labels = []
        predicted_labels = []

        if epoch % 1 == 0 and epoch != 0:
            TestStatic(model, test_loader)

        model.train()
        
        for file_id, api, api_counts, remove_dup, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', ncols=100):

            inputs = api_counts.to(torch.float).to(device())
            labels = labels.to(device())

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = F.cross_entropy(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            true_labels.extend(labels.tolist())
            _, predicted = torch.max(outputs, 1)
            predicted_labels.extend(predicted.tolist())

        avg_loss = running_loss / len(train_loader)

        StatisticLoss.append(avg_loss)

        recall = recall_score(true_labels, predicted_labels, average='weighted')
        f1 = f1_score(true_labels, predicted_labels, average='weighted')
        accuracy = accuracy_score(true_labels, predicted_labels)

        print(f'Epoch [{epoch + 1}/{epochs}] - Loss: {avg_loss:.4f} - Recall: {recall:.4f} - F1-Score: {f1:.4f} - Accuracy: {accuracy:.4f}')

    model_save(folder_path, (model,))
    save_loss(folder_path, StatisticLoss, "StatisticLoss")

    recall, f1, accuracy, precision = TestStatic(model, test_loader)
    model_info_save(folder_path, recall, f1, accuracy, precision)

    print('Statistic Train finished')


def TestStatic(model, test_loader):
    model.eval()

    true_labels = []
    predicted_labels = []

    with torch.no_grad():  # 不需要计算梯度
        for file_id, api, api_counts, remove_dup, labels in test_loader:

            # 设置device
            inputs = api_counts.to(torch.float).to(device())
            labels = labels.to(device())

            # 获取模型输出结果
            outputs = model(inputs)

            _, predicted = torch.max(outputs, 1)
            
            # 保存真实标签和预测标签以计算指标
            true_labels.extend(labels.tolist())
            predicted_labels.extend(predicted.tolist())

    # 计算召回率、F1-Score 和准确度
    recall = recall_score(true_labels, predicted_labels, average='weighted')
    f1 = f1_score(true_labels, predicted_labels, average='weighted')
    accuracy = accuracy_score(true_labels, predicted_labels)
    precision = precision_score(true_labels, predicted_labels, average='weighted')
    conf_matrix = confusion_matrix(true_labels, predicted_labels)

    # 输出测试指标
    print(conf_matrix)
    print(f'Test Accuracy: {accuracy:.4f}')
    print(f'Test Recall: {recall:.4f}')
    print(f'Test F1-Score: {f1:.4f}')
    print(f'Test precision: {precision:.4f}')

    return recall, f1, accuracy, precision


def SetSeed():
    # 设置随机种子
    setup_seed(42)
    torch_state_seed_value = torch.initial_seed()
    print("Torch Random Seed:", torch_state_seed_value)

    rng_state = np.random.get_state()
    rng_state_seed_value = rng_state[1][0]
    print("NumPy Random Seed:", rng_state_seed_value)

    random_state = random.getstate()
    random_state_seed_value = random_state[1][0]
    print("Python Random Seed:", random_state_seed_value)

def BuildDataloader():
    # 构建 train_dataloader
    train_dataset = ALiDataset(train=True)
    train_dataloader = DataLoader(train_dataset, batch_size=128, 
                                  shuffle=True, collate_fn=collate_fn_vocab, drop_last=True)

    # 构建 test_dataloader
    test_dataset = ALiDataset(train=False)
    test_dataloader = DataLoader(test_dataset, batch_size=128, 
                                 shuffle=True, collate_fn=collate_fn_vocab, drop_last=False)
    return train_dataloader, test_dataloader


if __name__ == '__main__':

    SetSeed()
    
    train_dataloader, test_dataloader = BuildDataloader()

    # 创建保存模型文件夹
    folder_path = create_folder(os.path.join(current_dir, "model_file"))

    # 训练
    TrainStatic(train_dataloader,test_dataloader, folder_path)
