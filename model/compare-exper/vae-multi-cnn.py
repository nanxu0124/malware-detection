import sys
import os

current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)

import torch
import configparser
from tqdm import tqdm
from torch.optim import Adam
import torch.nn.functional as F
from utils.utils import device, model_save, model_save_v2, SimiliarError, save_loss, model_info_save, create_folder, setup_seed
from sklearn.metrics import recall_score, f1_score, accuracy_score, precision_score, confusion_matrix
import random
import numpy as np
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from data.ali_data.ali_dataset import ALiDataset, collate_fn_vocab
from data.ali_data.ali_dataset import vocab_pkl
config = configparser.ConfigParser()
config.read(os.path.join(project_dir, os.path.join("config", "config.ini")))

vocab_size = len(vocab_pkl)
dim = int(config['data']['embedding_dim'])
max_len = int(config['data']['sequence_max_len'])

class VAE_MultiCNN(nn.Module):
    def __init__(self):
        super(VAE_MultiCNN, self).__init__()

        self.embedding = nn.Embedding(vocab_size, dim, padding_idx=vocab_pkl.PAD)
        self.encoder_conv = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),

            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1), 
            nn.BatchNorm2d(32),
            nn.ReLU(),

            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
        )

        self.encoder_lstm = nn.Sequential(
            nn.LSTM(input_size=64, hidden_size=30, batch_first=True, bidirectional=True)
        )

        self.decoder_fc1 = nn.Sequential(
            nn.Linear(60, 1920),
            nn.ReLU(),
            nn.Linear(1920, 64 * 625),
            nn.ReLU(),
        )

        self.decoder_conv = nn.Sequential(
            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),

            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),

            nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )
        self.cnn1_1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(3, 8), stride=1, padding=(1, 0))
        self.cnn1_2 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(4, 8), stride=1)
        self.cnn1_3 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(5, 8), stride=1, padding=(2, 0))
        self.lstm = nn.LSTM(input_size=384, hidden_size=100, batch_first=True, bidirectional=True)

        self.cla = nn.Sequential(
            nn.Linear(260, 6),
        )

    def encoder_mu(self, x):
        _, (h_n, c_n) = self.encoder_lstm(x)
        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]
        x = torch.cat([output_fw, output_bw], dim=-1)
        return x
      
    def encoder_log(self, x):
        _, (h_n, c_n) = self.encoder_lstm(x)
        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]
        x = torch.cat([output_fw, output_bw], dim=-1)
        return x

    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def encoder(self, x):
        x = self.embedding(x)
        x = x.view(x.size(0), 1, max_len, dim)
        embed_x = x

        x = self.encoder_conv(embed_x)
        x = x.squeeze(-1).permute(0, 2, 1)
        mu = self.encoder_mu(x)
        log = self.encoder_log(x)
        z = self.reparameterize(mu, log)
        return embed_x, mu, z

    def decoder(self, x):
        x = self.decoder_fc1(x)
        x = x.view(x.size(0), 64, 625, 1)
        x = self.decoder_conv(x)
        return x
    
    def multi_cnn(self, x):
        x = self.embedding(x)
        x= x.unsqueeze(1)

        pad = nn.ZeroPad2d(padding=(0, 0, 2, 1))
        x_pad = pad(x)

        x_name_cnn1 = F.relu(self.cnn1_1(x)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn2 = F.relu(self.cnn1_2(x_pad)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn3 = F.relu(self.cnn1_3(x)).squeeze(-1).permute(0, 2, 1)
        x = torch.cat([x_name_cnn1, x_name_cnn2, x_name_cnn3], dim=-1)
        x, (h_n, c_n) = self.lstm(x)
        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]
        x = torch.cat([output_fw, output_bw], dim=-1)
        return x

    def forward(self, x, y):
        embed_x, mu, z = self.encoder(x)
        recon_x = self.decoder(z)
        multi_cnn_output = self.multi_cnn(x)

        latent = torch.cat([mu, multi_cnn_output], dim=1)
        label_output = self.cla(latent)
        return embed_x, recon_x, label_output


def Train(train_loader, test_loader, folder_path):
    print("VAE-MultiCNN Train begin")

    epochs = 20
    lr = 0.005
    vae_loss_list = []

    net = VAE_MultiCNN().to(device())
    net_optim = Adam(net.parameters(), lr)

    for epoch in range(epochs):

        true_labels = []
        predicted_labels = []
        vae_running_loss = 0.0
        cla_running_loss = 0.0

        if epoch % 1 == 0 and epoch != 0:
            TestNET(net, test_loader)
        net.train()
        
        for file_id, api, api_counts, remove_dup, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', ncols=100):

            inputs = remove_dup.to(device())
            labels = labels.to(device())
            api_counts = api_counts.to(device())

            net.zero_grad()
            embed_x, recon_x, label_output = net(inputs, api_counts)

            recon_loss = F.mse_loss(embed_x, recon_x)
            KL_loss = 0.0 # -0.5 * torch.sum(1 + log - mu.pow(2) - log.exp())
            vae_loss = recon_loss + KL_loss
            cla_loss = F.cross_entropy(label_output, labels)

            total_loss = vae_loss + cla_loss
            total_loss.backward()
            net_optim.step()

            vae_running_loss += vae_loss.item()
            cla_running_loss += cla_loss.item()

            true_labels.extend(labels.tolist())
            _, predicted = torch.max(label_output, 1)
            predicted_labels.extend(predicted.tolist())

        vae_avg_loss = vae_running_loss / len(train_loader)
        cla_avg_loss = cla_running_loss / len(train_loader)

        vae_loss_list.append(vae_avg_loss + cla_avg_loss)

        recall = recall_score(true_labels, predicted_labels, average='weighted')
        f1 = f1_score(true_labels, predicted_labels, average='weighted')
        accuracy = accuracy_score(true_labels, predicted_labels)

        print(f'Epoch [{epoch + 1}/{epochs}] - vae_avg_loss: {vae_avg_loss:.4f} - cla_avg_loss: {cla_avg_loss:.4f} - Recall: {recall:.4f} - F1-Score: {f1:.4f} - Accuracy: {accuracy:.4f}')
    model_save(folder_path, (net,))
    save_loss(folder_path, vae_loss_list, "VAE-MultiCNN_loss_list")

    recall, f1, accuracy, precision = TestNET(net, test_loader)
    model_info_save(folder_path, recall, f1, accuracy, precision)

    print('VAE-MultiCNN Train finished')


def TestNET(net, test_loader):
    net.eval()

    true_labels = []
    predicted_labels = []

    with torch.no_grad():  # 不需要计算梯度
        for file_id, api, api_counts, remove_dup, labels in test_loader:

            inputs = remove_dup.to(device())
            labels = labels.to(device())
            api_counts = api_counts.to(device())

            embed_x, recon_x, label_output = net(inputs, api_counts)

            _, predicted = torch.max(label_output, 1)
            
            # 保存真实标签和预测标签以计算指标
            true_labels.extend(labels.cpu().numpy())
            predicted_labels.extend(predicted.cpu().numpy())    

    conf_matrix = confusion_matrix(true_labels, predicted_labels)
    # 计算召回率、F1-Score 和准确度
    recall = recall_score(true_labels, predicted_labels)
    f1 = f1_score(true_labels, predicted_labels)
    precision = precision_score(true_labels, predicted_labels)
    accuracy = accuracy_score(true_labels, predicted_labels)

    # 输出测试指标
    print("Confusion Matrix:")
    print(conf_matrix)
    print(f'Test Accuracy: {accuracy:.4f}')
    print(f'Test Recall: {recall:.4f}')
    print(f'Test F1-Score: {f1:.4f}')
    print(f'Test precision: {precision:.4f}')

    return recall, f1, accuracy, precision


def SetSeed():
    # 设置随机种子
    setup_seed(42)
    torch_state_seed_value = torch.initial_seed()
    print("Torch Random Seed:", torch_state_seed_value)

    rng_state = np.random.get_state()
    rng_state_seed_value = rng_state[1][0]
    print("NumPy Random Seed:", rng_state_seed_value)

    random_state = random.getstate()
    random_state_seed_value = random_state[1][0]
    print("Python Random Seed:", random_state_seed_value)

def BuildDataloader():
    # 构建 train_dataloader
    train_dataset = ALiDataset(train=True)
    train_dataloader = DataLoader(train_dataset, batch_size=128, 
                                  shuffle=True, collate_fn=collate_fn_vocab, drop_last=True)

    # 构建 test_dataloader
    test_dataset = ALiDataset(train=False)
    test_dataloader = DataLoader(test_dataset, batch_size=128, 
                                 shuffle=True, collate_fn=collate_fn_vocab, drop_last=False)
    return train_dataloader, test_dataloader

if __name__ == '__main__':

    SetSeed()
    
    train_dataloader, test_dataloader = BuildDataloader()

    # 创建保存模型文件夹
    folder_path = create_folder(os.path.join(current_dir, "model_file"))

    # 训练
    Train(train_dataloader,test_dataloader, folder_path)
