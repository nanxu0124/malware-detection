import sys
import os

current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)

import torch
import torch.nn as nn
import configparser
import torch.nn.functional as F

from data.ali_data import ali_dataset

# 创建一个配置解析器对象
config = configparser.ConfigParser()
# 读取INI文件
config.read('./config/config.ini')


vocab_size = len(ali_dataset.vocab_pkl)
dim = int(config['data']['embedding_dim'])
n_class = 8
max_len = int(config['data']['sequence_max_len'])



class API_Phrases(nn.Module):
    def __init__(self):
        super(API_Phrases, self).__init__()

        self.embedder1 = nn.Embedding(vocab_size, dim, padding_idx=ali_dataset.vocab_pkl.PAD)

        self.cnn1_1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(3, dim), stride=1, padding=(1, 0))
        self.cnn1_2 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(4, dim), stride=1)
        self.cnn1_3 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(5, dim), stride=1, padding=(2, 0))

        # 第二部分 全局特征
        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),

            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),

            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),

            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )



        self.lstm = nn.LSTM(input_size=640, hidden_size=128, bidirectional=True, batch_first=True)

        self.lin1 = nn.Linear(256, 128)
        self.lin2 = nn.Linear(128, 64)
        self.lin3 = nn.Linear(64, 8)


    def forward(self, x):

        x = self.embedder1(x)
        x= x.unsqueeze(1)

        pad = nn.ZeroPad2d(padding=(0, 0, 2, 1))
        x_pad = pad(x)

        x_name_cnn1 = F.relu(self.cnn1_1(x)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn2 = F.relu(self.cnn1_2(x_pad)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn3 = F.relu(self.cnn1_3(x)).squeeze(-1).permute(0, 2, 1)

        x_cnn2 = self.conv2(x)
        x_cnn2 = x_cnn2.view(256, 512, -1) 

        x = torch.cat([x_name_cnn1, x_name_cnn2, x_name_cnn3, x_cnn2], dim=-1)

        x, (h_n, c_n) = self.lstm(x)

        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]

        x = torch.cat([output_fw, output_bw], dim=-1)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.2, training=self.training)
        x = F.relu(self.lin2(x))
        x = F.dropout(x, p=0.2, training=self.training)
        x = F.sigmoid(self.lin3(x))

        return x