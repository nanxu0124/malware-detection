import sys
import os
current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)

import re
import torch
import pickle

import random
import numpy as np

import configparser
import pandas as pd
import torch.nn as nn

from models import *
from train import *
from data.ali_data.ali_dataset import ALiDataset, collate_fn_vocab
from utils.utils import device, create_folder, save_loss, model_info_save, plt_curve, setup_seed

from torch.optim import Adam
from torch.utils.data import Dataset, DataLoader


# 创建一个配置解析器对象
config = configparser.ConfigParser()
# 读取INI文件
config.read(os.path.join(project_dir, os.path.join("config", "config.ini")))

# 5291423553854095219
if __name__ == '__main__':
    
    setup_seed(int(config['data']['seed']))
    torch_state_seed_value = torch.initial_seed()
    print("Torch Random Seed:", torch_state_seed_value)

    rng_state = np.random.get_state()
    rng_state_seed_value = rng_state[1][0]
    print("NumPy Random Seed:", rng_state_seed_value)

    random_state = random.getstate()
    random_state_seed_value = random_state[1][0]
    print("Python Random Seed:", random_state_seed_value)

    # 构建 train_dataloader
    train_dataset = ALiDataset(train=True)
    train_dataloader = DataLoader(train_dataset, batch_size=int(config['API_phrases']['batch_size']), 
                                  shuffle=True, collate_fn=collate_fn_vocab, drop_last=True)

    # 构建 test_dataloader
    test_dataset = ALiDataset(train=False)
    test_dataloader = DataLoader(test_dataset, batch_size=int(config['API_phrases']['batch_size']), 
                                 shuffle=True, collate_fn=collate_fn_vocab, drop_last=True)

    # 定义模型
    Model = API_Phrases().to(device())

    # 参数设置
    optimizer = Adam(Model.parameters(), lr=float(config['API_phrases']['learning_rate']))

    # 设置loss
    criterion = nn.CrossEntropyLoss()

    # 创建保存模型文件夹
    folder_path = create_folder(os.path.join(current_dir, "model_file"))

    # 训练api_phrases
    api_phrases_losses = train(Model, train_dataloader,test_dataloader, criterion, optimizer, int(config['API_phrases']['epoch']), folder_path)

    # 加载模型
    # model.load_state_dict(torch.load(''))

    # 保存本次训练的loss到文件
    save_loss(folder_path, api_phrases_losses, "api_phrases_losses")

    # # 测试结果
    recall, f1, accuracy = test(Model, test_dataloader)

    # 保存测试结果
    model_info_save(folder_path=folder_path,  recall=recall, f1=f1, accuracy=accuracy, configfile=config)

    # 画图
    plt_curve(api_phrases_losses, int(config['API_phrases']['epoch']))
