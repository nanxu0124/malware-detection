import sys
import os
current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)

import configparser
from utils.utils import device, model_save, model_save_v2

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam
from tqdm import tqdm
from sklearn.metrics import recall_score, f1_score, accuracy_score

from models import *

# 创建一个配置解析器对象
config = configparser.ConfigParser()
# 读取INI文件
config.read(os.path.join(project_dir, os.path.join("config", "config.ini")))

Statistic_losses = []


def TrainMultiCNN(train_loader, test_loader, folder_path):
    print("MultiCNN Train begin")

    model = MultiCNN().to(device())
    MultiCNNLoss = []
    epochs = int(config['multi-cnn-vae']['epoch'])
    optimizer = Adam(model.parameters(), lr=float(config['multi-cnn-vae']['learning_rate']))

    for epoch in range(epochs):

        running_loss = 0.0
        true_labels = []
        predicted_labels = []

        if epoch % 1 == 0 and epoch != 0:
            recall, f1, accuracy = test(model, test_loader)
            # if accuracy > 0.91:
            #     model_save_v2(folder_path, (model, ), accuracy)

        model.train()
        
        for file_id, api, api_counts, remove_dup, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', ncols=100):

            inputs = api.to(device())
            labels = labels.to(device())

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = F.cross_entropy(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            true_labels.extend(labels.tolist())
            _, predicted = torch.max(outputs, 1)
            predicted_labels.extend(predicted.tolist())

        avg_loss = running_loss / len(train_loader)

        MultiCNNLoss.append(avg_loss)

        recall = recall_score(true_labels, predicted_labels, average='weighted')
        f1 = f1_score(true_labels, predicted_labels, average='weighted')
        accuracy = accuracy_score(true_labels, predicted_labels)

        print(f'Epoch [{epoch + 1}/{epochs}] - Loss: {avg_loss:.4f} - Recall: {recall:.4f} - F1-Score: {f1:.4f} - Accuracy: {accuracy:.4f}')

    model_save(folder_path, (model,))

    print('MultiCNN Train finished')

    return MultiCNNLoss

def test(model, test_loader):
    model.eval()

    true_labels = []
    predicted_labels = []

    with torch.no_grad():  # 不需要计算梯度
        for file_id, api, api_counts, remove_dup, labels in test_loader:

            # 设置device
            inputs = api.to(device())
            labels = labels.to(device())

            # 获取模型输出结果
            outputs = model(inputs)

            _, predicted = torch.max(outputs, 1)
            
            # 保存真实标签和预测标签以计算指标
            true_labels.extend(labels.tolist())
            predicted_labels.extend(predicted.tolist())

    # 计算召回率、F1-Score 和准确度
    recall = recall_score(true_labels, predicted_labels, average='weighted')
    f1 = f1_score(true_labels, predicted_labels, average='weighted')
    accuracy = accuracy_score(true_labels, predicted_labels)

    # 输出测试指标
    print(f'Test Accuracy: {accuracy:.4f}')
    print(f'Test Recall: {recall:.4f}')
    print(f'Test F1-Score: {f1:.4f}')

    return recall, f1, accuracy



def TrainVAE(train_loader, test_loader, folder_path):
    print("VAE Train begin")

    encoder = Encoder().to(device())
    cla = Classifier().to(device())

    encoderLoss = []
    claLoss = []
    epochs = int(config['multi-cnn-vae']['epoch'])
    encoder_optim = Adam(encoder.parameters(), lr=float(config['multi-cnn-vae']['learning_rate']))
    cla_optim = Adam(cla.parameters(), lr=float(config['multi-cnn-vae']['learning_rate']))

    for epoch in range(epochs):

        running_loss = 0.0
        true_labels = []
        predicted_labels = []

        if epoch % 1 == 0 and epoch != 0:
            recall, f1, accuracy = TestVAE(encoder, cla, test_loader)
            # if accuracy > 0.91:
            #     model_save_v2(folder_path, (model, ), accuracy)

        encoder.train()
        cla.train()
        
        for file_id, api, api_counts, remove_dup, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', ncols=100):

            inputs = api.to(device())
            labels = labels.to(device())
            api_counts = api_counts.to(device())

            encoder_optim.zero_grad()
            cla_optim.zero_grad()
            mu = encoder(inputs)
            latent = torch.cat((mu, api_counts), dim=1)
            outputs = cla(latent)
            loss = F.cross_entropy(outputs, labels)
            loss.backward()
            encoder_optim.step()
            cla_optim.step()

            running_loss += loss.item()
            true_labels.extend(labels.tolist())
            _, predicted = torch.max(outputs, 1)
            predicted_labels.extend(predicted.tolist())

        avg_loss = running_loss / len(train_loader)

        encoderLoss.append(avg_loss)

        recall = recall_score(true_labels, predicted_labels, average='weighted')
        f1 = f1_score(true_labels, predicted_labels, average='weighted')
        accuracy = accuracy_score(true_labels, predicted_labels)

        print(f'Epoch [{epoch + 1}/{epochs}] - Loss: {avg_loss:.4f} - Recall: {recall:.4f} - F1-Score: {f1:.4f} - Accuracy: {accuracy:.4f}')

    model_save(folder_path, (encoder, cla,))

    print('MultiCNN Train finished')

    return encoderLoss

def TestVAE(encoder, cla, test_loader):
    encoder.eval()
    cla.eval()

    true_labels = []
    predicted_labels = []

    with torch.no_grad():  # 不需要计算梯度
        for file_id, api, api_counts, remove_dup, labels in test_loader:

            # 设置device
            inputs = api.to(device())
            labels = labels.to(device())
            api_counts = api_counts.to(device())

            # 获取模型输出结果
            mu = encoder(inputs)
            latent = torch.cat((mu, api_counts), dim=1)
            outputs = cla(latent)

            _, predicted = torch.max(outputs, 1)
            
            # 保存真实标签和预测标签以计算指标
            true_labels.extend(labels.tolist())
            predicted_labels.extend(predicted.tolist())

    # 计算召回率、F1-Score 和准确度
    recall = recall_score(true_labels, predicted_labels, average='weighted')
    f1 = f1_score(true_labels, predicted_labels, average='weighted')
    accuracy = accuracy_score(true_labels, predicted_labels)

    # 输出测试指标
    print(f'Test Accuracy: {accuracy:.4f}')
    print(f'Test Recall: {recall:.4f}')
    print(f'Test F1-Score: {f1:.4f}')

    return recall, f1, accuracy


def TrainStatic(train_loader, test_loader, folder_path):
    print("Static Train begin")

    model = Statistic().to(device())
    StatisticLoss = []
    epochs = int(config['multi-cnn-vae']['epoch'])
    optimizer = Adam(model.parameters(), lr=float(config['multi-cnn-vae']['learning_rate']))

    for epoch in range(epochs):

        running_loss = 0.0
        true_labels = []
        predicted_labels = []

        if epoch % 1 == 0 and epoch != 0:
            recall, f1, accuracy = TestStatic(model, test_loader)
            # if accuracy > 0.91:
            #     model_save_v2(folder_path, (model, ), accuracy)

        model.train()
        
        for file_id, api, api_counts, remove_dup, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', ncols=100):

            inputs = api_counts.to(torch.float).to(device())
            labels = labels.to(device())

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = F.cross_entropy(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            true_labels.extend(labels.tolist())
            _, predicted = torch.max(outputs, 1)
            predicted_labels.extend(predicted.tolist())

        avg_loss = running_loss / len(train_loader)

        StatisticLoss.append(avg_loss)

        recall = recall_score(true_labels, predicted_labels, average='weighted')
        f1 = f1_score(true_labels, predicted_labels, average='weighted')
        accuracy = accuracy_score(true_labels, predicted_labels)

        print(f'Epoch [{epoch + 1}/{epochs}] - Loss: {avg_loss:.4f} - Recall: {recall:.4f} - F1-Score: {f1:.4f} - Accuracy: {accuracy:.4f}')

    model_save(folder_path, (model,))

    print('MultiCNN Train finished')

    return StatisticLoss

def TestStatic(model, test_loader):
    model.eval()

    true_labels = []
    predicted_labels = []

    with torch.no_grad():  # 不需要计算梯度
        for file_id, api, api_counts, remove_dup, labels in test_loader:

            # 设置device
            inputs = api_counts.to(torch.float).to(device())
            labels = labels.to(device())

            # 获取模型输出结果
            outputs = model(inputs)

            _, predicted = torch.max(outputs, 1)
            
            # 保存真实标签和预测标签以计算指标
            true_labels.extend(labels.tolist())
            predicted_labels.extend(predicted.tolist())

    # 计算召回率、F1-Score 和准确度
    recall = recall_score(true_labels, predicted_labels, average='weighted')
    f1 = f1_score(true_labels, predicted_labels, average='weighted')
    accuracy = accuracy_score(true_labels, predicted_labels)

    # 输出测试指标
    print(f'Test Accuracy: {accuracy:.4f}')
    print(f'Test Recall: {recall:.4f}')
    print(f'Test F1-Score: {f1:.4f}')

    return recall, f1, accuracy