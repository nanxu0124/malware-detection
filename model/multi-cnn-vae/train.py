import sys
import os
current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)

import torch
import configparser
from tqdm import tqdm
from torch.optim import Adam
import torch.nn.functional as F
from utils.utils import device, model_save, model_save_v2, SimiliarError, save_loss, model_info_save
from sklearn.metrics import recall_score, f1_score, accuracy_score, precision_score, confusion_matrix
from models import *

# 创建一个配置解析器对象
config = configparser.ConfigParser()
# 读取INI文件
config.read(os.path.join(project_dir, os.path.join("config", "config.ini")))

#####################################################################
#
#   TrainNET
#
#####################################################################
def TrainNET(train_loader, test_loader, folder_path):
    print("NET Train begin")

    epochs = 27
    lr = 0.001
    NET_LOSS = []

    net = NET().to(device())
    net_optim = Adam(net.parameters(), lr)

    for epoch in range(epochs):

        true_labels = []
        predicted_labels = []
        vae_running_loss = 0.0
        cla_running_loss = 0.0

        if epoch % 1 == 0 and epoch != 0:
            TestNET(net, test_loader)
        net.train()
        
        for file_id, api, api_counts, remove_dup, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', ncols=100):

            inputs = remove_dup.to(device())
            labels = labels.to(device())
            api_counts = api_counts.to(device())

            net.zero_grad()
            embed_x, recon_x, label_output = net(inputs, api_counts)

            recon_loss = F.mse_loss(embed_x, recon_x)
            KL_loss = 0.0 # -0.5 * torch.sum(1 + log - mu.pow(2) - log.exp())
            vae_loss = recon_loss + KL_loss
            cla_loss = F.cross_entropy(label_output, labels)

            total_loss = vae_loss + cla_loss
            total_loss.backward()
            net_optim.step()

            vae_running_loss += vae_loss.item()
            cla_running_loss += cla_loss.item()

            true_labels.extend(labels.tolist())
            _, predicted = torch.max(label_output, 1)
            predicted_labels.extend(predicted.tolist())

        vae_avg_loss = vae_running_loss / len(train_loader)
        cla_avg_loss = cla_running_loss / len(train_loader)

        NET_LOSS.append(vae_avg_loss + cla_avg_loss)

        recall = recall_score(true_labels, predicted_labels, average='weighted')
        f1 = f1_score(true_labels, predicted_labels, average='weighted')
        accuracy = accuracy_score(true_labels, predicted_labels)

        print(f'Epoch [{epoch + 1}/{epochs}] - vae_avg_loss: {vae_avg_loss:.4f} - cla_avg_loss: {cla_avg_loss:.4f} - Recall: {recall:.4f} - F1-Score: {f1:.4f} - Accuracy: {accuracy:.4f}')
    model_save(folder_path, (net,))
    save_loss(folder_path, NET_LOSS, "NET_LOSS")

    recall, f1, accuracy, precision = TestNET(net, test_loader)
    model_info_save(folder_path, recall, f1, accuracy, precision)

    print('NET Train finished')


def TestNET(net, test_loader):
    net.eval()

    true_labels = []
    predicted_labels = []
    misclassified_file_ids = []

    with torch.no_grad():  # 不需要计算梯度
        for file_id, api, api_counts, remove_dup, labels in test_loader:

            inputs = remove_dup.to(device())
            labels = labels.to(device())
            api_counts = api_counts.to(device())

            embed_x, recon_x, label_output = net(inputs, api_counts)

            _, predicted = torch.max(label_output, 1)
            
            # 保存真实标签和预测标签以计算指标
            true_labels.extend(labels.cpu().numpy())
            predicted_labels.extend(predicted.cpu().numpy())
            # 找到错误分类的样本
            # misclassified_indices = (predicted != labels).nonzero().squeeze()
            # misclassified_file_ids.extend([file_id[i].item() for i in misclassified_indices])           

    conf_matrix = confusion_matrix(true_labels, predicted_labels)
    # 计算召回率、F1-Score 和准确度
    recall = recall_score(true_labels, predicted_labels, average='macro')
    f1 = f1_score(true_labels, predicted_labels, average='weighted')
    precision = precision_score(true_labels, predicted_labels, average='weighted')
    accuracy = accuracy_score(true_labels, predicted_labels)

    # 输出测试指标
    print("Confusion Matrix:")
    print(conf_matrix)
    print(f'Test Accuracy: {accuracy:.4f}')
    print(f'Test Recall: {recall:.4f}')
    print(f'Test F1-Score: {f1:.4f}')
    print(f'Test precision: {precision:.4f}')
    # print("=========================================")
    # print(misclassified_file_ids)
    # print("=========================================")

    return recall, f1, accuracy, precision
