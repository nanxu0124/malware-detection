import sys
import os

current_dir = os.path.dirname(__file__)
project_dir = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_dir)

import torch
import torch.nn as nn
import configparser
import torch.nn.functional as F
from data.ali_data.ali_dataset import vocab_pkl
config = configparser.ConfigParser()
config.read(os.path.join(project_dir, os.path.join("config", "config.ini")))

vocab_size = len(vocab_pkl)
dim = int(config['data']['embedding_dim'])
max_len = int(config['data']['sequence_max_len'])

class NET(nn.Module):
    def __init__(self):
        super(NET, self).__init__()

        self.embedding = nn.Embedding(vocab_size, dim, padding_idx=vocab_pkl.PAD)
        self.encoder_conv = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),

            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1), 
            nn.BatchNorm2d(32),
            nn.ReLU(),

            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
        )

        self.encoder_lstm = nn.Sequential(
            nn.LSTM(input_size=64, hidden_size=30, batch_first=True, bidirectional=True)
        )

        self.decoder_fc1 = nn.Sequential(
            nn.Linear(60, 1920),
            nn.ReLU(),
            nn.Linear(1920, 64 * 625),
            nn.ReLU(),
        )

        self.decoder_conv = nn.Sequential(
            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),

            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),

            nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )

        self.cnn1_1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(3, 8), stride=1, padding=(1, 0))
        self.cnn1_2 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(4, 8), stride=1)
        self.cnn1_3 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(5, 8), stride=1, padding=(2, 0))
        self.lstm = nn.LSTM(input_size=384, hidden_size=100, batch_first=True, bidirectional=True)

        self.cla = nn.Sequential(
            nn.Linear(300, 6),
        )

        self.linear1 = nn.Linear(80, 40)


    def encoder_mu(self, x):
        _, (h_n, c_n) = self.encoder_lstm(x)
        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]
        x = torch.cat([output_fw, output_bw], dim=-1)
        return x
      
    def encoder_log(self, x):
        _, (h_n, c_n) = self.encoder_lstm(x)
        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]
        x = torch.cat([output_fw, output_bw], dim=-1)
        return x

    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def encoder(self, x):
        x = self.embedding(x)
        x = x.view(x.size(0), 1, max_len, dim)
        embed_x = x

        x = self.encoder_conv(embed_x)
        x = x.squeeze(-1).permute(0, 2, 1)
        mu = self.encoder_mu(x)
        log = self.encoder_log(x)
        z = self.reparameterize(mu, log)
        return embed_x, mu, z

    def decoder(self, x):
        x = self.decoder_fc1(x)
        x = x.view(x.size(0), 64, 625, 1)
        x = self.decoder_conv(x)
        return x
    
    def multi_cnn(self, x):
        x = self.embedding(x)
        x= x.unsqueeze(1)

        pad = nn.ZeroPad2d(padding=(0, 0, 2, 1))
        x_pad = pad(x)

        x_name_cnn1 = F.relu(self.cnn1_1(x)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn2 = F.relu(self.cnn1_2(x_pad)).squeeze(-1).permute(0, 2, 1)
        x_name_cnn3 = F.relu(self.cnn1_3(x)).squeeze(-1).permute(0, 2, 1)
        x = torch.cat([x_name_cnn1, x_name_cnn2, x_name_cnn3], dim=-1)
        x, (h_n, c_n) = self.lstm(x)
        output_fw = h_n[-2, :, :]
        output_bw = h_n[-1, :, :]
        x = torch.cat([output_fw, output_bw], dim=-1)
        return x

    def forward(self, x, y):
        embed_x, mu, z = self.encoder(x)
        recon_x = self.decoder(z)
        multi_cnn_output = self.multi_cnn(x)

        y = y.to(torch.float32)
        y = self.linear1(y)
        
        latent = torch.cat([y, mu, multi_cnn_output], dim=1)
        label_output = self.cla(latent)

        return embed_x, recon_x, label_output