{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总计13886条数据\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每种label各有多少个\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "print(label_counts)\n",
    "\n",
    "# 各个label的数量\n",
    "# 0    4978\n",
    "# 5    4289\n",
    "# 7    1486\n",
    "# 2    1196\n",
    "# 3     820\n",
    "# 6     515\n",
    "# 1     502\n",
    "# 4     100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# 在lebel为0 5 7 2 3 6 1 的数据中，每个label随机取出500条数据存到新的df中，随机种子42\n",
    "###########################################################################\n",
    "\n",
    "selected_df = df[df['label'].isin([0, 5, 7, 2, 3, 6, 1])]\n",
    "\n",
    "# 随机取出每个label的1196条数据\n",
    "random_samples_per_label = 500\n",
    "sampled_df = selected_df.groupby('label').apply(lambda x: x.sample(n=random_samples_per_label, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "#sampled_df\n",
    "# 0    500\n",
    "# 1    500\n",
    "# 2    500\n",
    "# 3    500\n",
    "# 5    500\n",
    "# 6    500\n",
    "# 7    500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# 5换成4 6换成5 7换成6\n",
    "###################################\n",
    "\n",
    "sampled_df.loc[sampled_df['label'] == 5, 'label'] = 4\n",
    "\n",
    "sampled_df.loc[sampled_df['label'] == 6, 'label'] = 5\n",
    "\n",
    "sampled_df.loc[sampled_df['label'] == 7, 'label'] = 6\n",
    "\n",
    "# label\n",
    "# 0    500\n",
    "# 1    500\n",
    "# 2    500\n",
    "# 3    500\n",
    "# 4    500\n",
    "# 5    500\n",
    "# 6    500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.to_csv('./data/data_cla6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# # 计算api列中每个字符串的长度\n",
    "# ###########################\n",
    "# api_lengths = sampled_df['api'].apply(lambda x: len(x))\n",
    "\n",
    "# # 将长度按照步长为1000进行分组\n",
    "# length_bins = range(0, api_lengths.max() + 10000, 10000)\n",
    "# api_length_groups = pd.cut(api_lengths, bins=length_bins)\n",
    "\n",
    "# # 统计各个分组的出现次数\n",
    "# length_counts = api_length_groups.value_counts().sort_index()\n",
    "# # 将统计情况保存到文件\n",
    "# length_counts.to_csv('length_counts_api.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################\n",
    "# #  计算remove_dup列中每个字符串的长度\n",
    "# ###################################\n",
    "# api_lengths = sampled_df['remove_dup'].apply(lambda x: len(x))\n",
    "\n",
    "# # 将长度按照步长为1000进行分组\n",
    "# length_bins = range(0, api_lengths.max() + 10000, 10000)\n",
    "# api_length_groups = pd.cut(api_lengths, bins=length_bins)\n",
    "\n",
    "# # 统计各个分组的出现次数\n",
    "# length_counts = api_length_groups.value_counts().sort_index()\n",
    "# # 将统计情况保存到文件\n",
    "# length_counts.to_csv('length_counts_remove_dup.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/data_cla6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# 统计api列中最长相同子串的长度（前10位）\n",
    "#####################################\n",
    "\n",
    "# 将单词按空格分割并转换为列表\n",
    "word_lists = df['api'].str.split()\n",
    "\n",
    "# 找出相邻且重复的单词\n",
    "repeated_words = []\n",
    "for words in word_lists:\n",
    "    current_word = ''\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        if word == current_word:\n",
    "            current_length += 1\n",
    "        else:\n",
    "            current_word = word\n",
    "            current_length = 1\n",
    "        repeated_words.append((current_word, current_length))\n",
    "\n",
    "# 根据重复单词的长度降序排序\n",
    "repeated_words.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 去除重复的单词，只保留出现次数最高的\n",
    "unique_repeated_words = {}\n",
    "for word, length in repeated_words:\n",
    "    if word not in unique_repeated_words or length > unique_repeated_words[word]:\n",
    "        unique_repeated_words[word] = length\n",
    "\n",
    "# 获取前10个最长的重复单词\n",
    "top_10_longest_repeated_words = sorted(unique_repeated_words.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "\n",
    "# 输出最长的前10个单词及其内容和长度\n",
    "print(\"相邻且重复的单词最长的前10位及其内容:\")\n",
    "for idx, (word, length) in enumerate(top_10_longest_repeated_words, start=1):\n",
    "    print(f\"{idx}: 单词 '{word}' 出现次数: {length}\")\n",
    "\n",
    "# 相邻且重复的单词最长的前10位及其内容:\n",
    "# 1: 单词 'NtDelayExecution' 出现次数: 20004\n",
    "# 2: 单词 'timeGetTime' 出现次数: 9950\n",
    "# 3: 单词 'NtWriteFile' 出现次数: 9552\n",
    "# 4: 单词 'LdrGetDllHandle' 出现次数: 4988\n",
    "# 5: 单词 'NtReadFile' 出现次数: 4958\n",
    "# 6: 单词 'GetFileAttributesW' 出现次数: 4867\n",
    "# 7: 单词 'GetSystemTimeAsFileTime' 出现次数: 4840\n",
    "# 8: 单词 'NtClose' 出现次数: 4519\n",
    "# 9: 单词 'NtAllocateVirtualMemory' 出现次数: 4487\n",
    "# 10: 单词 'NtProtectVirtualMemory' 出现次数: 4090\n",
    "# 11: 单词 'RegSetValueExA' 出现次数: 3932\n",
    "# 12: 单词 'CryptDecrypt' 出现次数: 3361\n",
    "# 13: 单词 'GetCursorPos' 出现次数: 3347\n",
    "# 14: 单词 '__exception__' 出现次数: 2980\n",
    "# 15: 单词 'NtReadVirtualMemory' 出现次数: 2138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# 按照2:8的比例随机分割数据\n",
    "#####################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假设sampled_df是你的数据框\n",
    "# 将数据分为训练集（80%）和测试集（20%）\n",
    "train_df, test_df = train_test_split(sampled_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
